\section{The Control Problem}
Here the system under investigation is a Bose-Einstein condensate placed in a one-dimensional optical lattice, which is well described by the one-dimensional Bose-Hubbard Hamiltonian
\begin{equation}
	\hat{H} = - t \sum_{j=1}^{L-1} \Bigl(\hat{a}_{j}^{\dag} \hat{a}_{j+1} + +\hatÂ¥{a}_{j+1}^\dagger \hat{a}_j \Bigr) + \frac{U}{2} \sum_{j=1}^L \hat{n}_j ( \hat{n}_j -1 ),
\end{equation}
where \textit{L} is the length of the system. \textit{t} and \textit{U} are the tunneling and interaction matrix elements, which can be manipulated by changing the depth of the optical lattice \cite{bloch2008many}. This system has two quantum phases for $t=0$ and $U=0$, which are the Mott insulator and superfluid respectively.

In this work we consider a state transfer from the superfluid into the Mott insulator by manipulating the ratio between $U(t)/t(t)$, which may be mapped back to manipulating the lattice depth \cite{bloch2008many}. For convience we set $t=1$ and take $U(t)$ to be the control parameter $u(t)$ so the control Hamiltonian becomes linear $H(u(t))=H_0+u(t)H_U$, where $H_0$ is the drift or tunneling part and $H_U$ is the controllable on-site interaction.

As mentioned above we discuss a state-to-state problem. In order to find a control $u(t)$ that achevies the transfer the problem is expressed a minimization of a cost functional $\hat{J}(u(t))$,
\begin{equation}
\hat{J}(u(t))=\frac{1}{2} \left( 1-|\braket{\psi_{\mathrm{t}} | \psi (T)}|^2 \right) \label{eq:infidelityCost}
\end{equation}
where $T$ is the duration of the control sequence. In the first term we have the fidelity $F=|\braket{\psi_{\mathrm{t}} | \psi (T)}|^2$ and $1-F$ is the infidelity. \textbf{HAR VI INGEN REGULARIZERING?} Since the control functions determine the time evolution, one must find the set of controls bringing the final state as close as possible to the target state. In practice, very few optimal control problems can be solved analytically, however, expressing the problem as a minimization enables the use of well established frameworks from mathematical optimization theory. This theory requires two primary components i) the ability to effectivly the cost in  Eq. (\ref{eq:infidelityCost}) many times and ii) access the the gradient of $\hat{J}(u(t))$.

\section{Tensor-Network Descriptions}
For complex many-body systems the Hilbert space grows too large for standard descriptions of states. Due to the combinatorial nature of the Bose-Hubbard model its corresponding Hilbert space scales exponentially with the system size. Matrix Products States parametrize states as networks of tensors.

Mention relation to lattices ...

A general state can be decomposed into a tensor network through a series of Schmidt decompositions, where eigenstates barely contributing to the overall state can be omitted resulting in a truncation of the dimensions of the tensor. The truncation along with an area law scaling of entropy with the system results in matrix product states only requiring to consider a small corner of the full Hilbert space.

Several methods exists for time-evolving tensor networks, however, most of them are variants of the same core ideas originally derived from the DMRG algorithm. The tDMRG algorithm employs a Trotter expansion of the propagator in order to evolve the state by applying a series of site-specific gate operations to the state.

Describe tailored tDMRG algorithm ...

\section{Quantum Optimal Control}
In this section we discuss how to calculate the gradient of Eq. (\ref{eq:infidelityCost}), which is required for performing the numerical minimization. This gradient is typically calculated using the \textsc{grape} algorithm \cite{khaneja2005optimal}.

GRAPE is a popular method for calculating gradients of optimal control cost functionals . The method has successfully been applied to EXAMPLES systems. In GRAPE the control function is discretized in time-steps of  $\Delta t$. While the gradient of the cost function in the original algorithm was derived to $O(\Delta t ^2)$ precision, a series of higher order corrections were added in \cite{de2011second}. The derivative of the cost function \eqref{eq:infidelityCost} with respect to the time-discretized control function is
\begin{equation}
	\frac{\partial J}{\partial u_n (t_j)}  = - \Re \Braket{\chi (t_j) | i  \frac{\partial \hat{\mathcal{U}}_{t_j}}{\partial u_n (t_j)} | \psi (t_{j-1})} \; , \label{eq:CostDeriv}
\end{equation}
where $\ket{\chi (T)} \equiv i \ket{\psi_{\mathrm{target}}} \braket{\psi_{\mathrm{target}} | \psi (T)}$ must be propagated back in time to obtain $\ket{\chi (t_j)}$.
The derivative of the propagator with respect to the control is given by
\begin{align}
	\frac{\partial \hat{\mathcal{U}}_{j}}{\partial u_n (t_j)} &= e^{-i \hat{H} (u_n (t_j)) \Delta t} \nonumber \\ 
	 \times \sum_{k = 0}^{\infty } &  \frac{i^{k-1} \Delta t^{k+1}}{(k+1)!} \left[ \hat{H} (u_n (t_j)) , \frac{\partial \hat{H} (u_n (t_j))}{\partial u_n (t_j)}  \right]_k \; , \label{eq:PropDeriv}
\end{align}
where the zeroth order term of the recursive commutator produces the gradient of the original GRAPE algorithm.

Calculating the propagator after each control update is an expensive procedure, as exponentiating the Hamiltonian \eqref{eq:ControlHamiltonians} is non-trivial. The Hamiltonian can be exponentiated term-wise through the Suzuki-Trotter expansion
\begin{equation}
		e ^{( \hat{H}_n + \hat{H}_0  ) \delta } = e^{  \hat{H}_n \delta /2  } e^{ \hat{H}_0 \delta } e^{ \hat{H}_n \delta /2 } + O(\delta^3) \; , \label{eq:SuzukiTrotter}
\end{equation}
where the error is due to any non-commutativity of the operators.
Thus, the propagator can be updated efficiently, as only $e^{ \hat{H}_n \delta /2 }$ must be re-calculated as $u_n (t)$ is updated. Additionally, Trotter-expanding the propagator is a necessary step for conducting time-evolution through the tDMRG algorithm. 

Further improvements in the cost of computing the propagator can be found if $\hat{H}_n$ is diagonal, as the exponentiation becomes trivial. Choosing a diagonal control Hamiltonian also has profound impact on the  derivative of the propagator, as all higher-order contributions vanish.\\
Consider a Suzuki-Trotter expanded propagator, where $\hat{H}_n (u_n (t))$ is evaluated at either side of the time-step for increased accuracy
\begin{align}
	\hat{\mathcal{U}}_{j}^{\mathrm{ST}} &\equiv e^{ -i  \hat{H}_n (u (t_j)) \Delta t /2 } \; e^{ -i \hat{H}_0 \Delta t } \; e^{ -i  \hat{H}_n (u (t_{j-1}))  \Delta t /2 } \\
	& \equiv \hat{\mathcal{U}}_{j}^{(n)} \hat{\mathcal{U}}_{j}^{(0)} \hat{\mathcal{U}}_{j-1}^{(n)} \; .
\end{align}
Both $\mathcal{U}_{j}^{\mathrm{ST}}$ and $\mathcal{U}_{j+1}^{\mathrm{ST}}$ contribute to the cost derivative due to the split-step of the control.
The derivative of $\mathcal{U}_{j}^{\mathrm{ST}}$ according to eq. \eqref{eq:PropDeriv} is
\begin{align}
	\frac{\partial \hat{\mathcal{U}}_{j}^{\mathrm{ST}}}{\partial u_n (t_j)} &=  \frac{\partial \hat{\mathcal{U}}_{j}^{(n)}}{\partial u_n (t_j)} \hat{\mathcal{U}}_{j}^{(0)} \hat{\mathcal{U}}_{j-1}^{(n)} \nonumber \\
	&= e^{ -i  \hat{H}_n (u (t_j)) \Delta t /2 } \left( -i \hat{H}_n (u_n (t_j)) \Delta t /2 \right) \hat{\mathcal{U}}_{j}^{(0)} \hat{\mathcal{U}}_{j-1}^{(n)} \nonumber \\
	&= \left( -i \hat{H}_n (u_n (t_j)) \Delta t /2 \right) \hat{\mathcal{U}}_{j}^{\mathrm{ST}} \; . \label{eq:STpropderiv1}
\end{align}
Since $\hat{H}_n$ is diagonal, the recursive commutator is vanishing for $k > 0$, which causes all higher-order contributions to the derivative of the propagator to drop out.\\
Likewise, the derivative of the second propagator is
\begin{equation}
	\frac{\partial \hat{\mathcal{U}}_{j+1}^{\mathrm{ST}}}{\partial u_n (j)} =  \hat{\mathcal{U}}_{j+1}^{\mathrm{ST}} \left( -i \hat{H}_n (u_n (t_j)) \Delta t /2 \right) \; . \label{eq:STpropderiv2}
\end{equation}
Inserting the derivatives of eq. \eqref{eq:STpropderiv1} and \eqref{eq:STpropderiv2} into the derivative of the cost (eq. \eqref{eq:CostDeriv}) yields
\begin{align}
	\frac{\partial J}{\partial u_n (t_j)} &= - \Re \Braket{\chi (t_j) |  \left(  \hat{H}_n (u_n (t_j)) \Delta t /2 \right) \hat{\mathcal{U}}_{j}^{\mathrm{ST}} | \psi (t_{j-1})} \nonumber \\
	& \quad - \Re \Braket{\chi (t_{j+1}) | \hat{\mathcal{U}}_{j+1}^{\mathrm{ST}} \left(  \hat{H}_n (u_n (t_j)) \Delta t /2 \right) | \psi (t_{j})} \nonumber \\
	&= - \Re \Braket{\chi (t_j) | \hat{H}_n (u_n (t_j)) \Delta t | \psi (t_{j})} \; . \label{eq:STcostgrad}
\end{align}  
Thus, the combination of the Suzuki-Trotter expansion and a diagonal control Hamiltonian eliminates all higher order contributions to the gradient. Thereby, the gradient of the cost is exact up to the order of the expansion.