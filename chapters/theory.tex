\section{The Control Problem}
Here the system under investigation is a Bose-Einstein condensate placed in a one-dimensional optical lattice, which is well described by the one-dimensional Bose-Hubbard Hamiltonian
\begin{equation}
	\hat{H} = - t \sum_{j=1}^{L-1} \Bigl(\hat{a}_{j}^{\dag} \hat{a}_{j+1} + +\hatÂ¥{a}_{j+1}^\dagger \hat{a}_j \Bigr) + \frac{U}{2} \sum_{j=1}^L \hat{n}_j ( \hat{n}_j -1 ),
\end{equation}
where \textit{L} is the length of the system. \textit{t} and \textit{U} are the tunneling and interaction matrix elements, which can be manipulated by changing the depth of the optical lattice \cite{bloch2008many}. This system has two quantum phases for $t=0$ and $U=0$, which are the Mott insulator and superfluid respectively.

In this work we consider a state transfer from the superfluid into the Mott insulator by manipulating the ratio between $U(t)/t(t)$, which may be mapped back to manipulating the lattice depth \cite{bloch2008many}. For convience we set $t=1$ and take $U(t)$ to be the control parameter $u(t)$ so the control Hamiltonian becomes linear $H(u(t))=H_0+u(t)H_U$, where $H_0$ is the drift or tunneling part and $H_U$ is the controllable on-site interaction.

As mentioned above we discuss a state-to-state problem. In order to find a control $u(t)$ that achevies the transfer the problem is expressed a minimization of a cost functional $\hat{J}(u(t))$,
\begin{equation}
\hat{J}(u(t))=\frac{1}{2} \left( 1-|\braket{\psi_{\mathrm{t}} | \psi (T)}|^2 \right) \label{eq:infidelityCost}
\end{equation}
where $T$ is the duration of the control sequence. In the first term we have the fidelity $F=|\braket{\psi_{\mathrm{t}} | \psi (T)}|^2$ and $1-F$ is the infidelity. \textbf{HAR VI INGEN REGULARIZERING?} Since the control functions determine the time evolution, one must find the set of controls bringing the final state as close as possible to the target state. In practice, very few optimal control problems can be solved analytically, however, expressing the problem as a minimization enables the use of well established frameworks from mathematical optimization theory. This theory requires two primary components i) the ability to effectivly the cost in  Eq. (\ref{eq:infidelityCost}) many times and ii) access the the gradient of $\hat{J}(u(t))$.

\section{Tensor-Network Descriptions}
Quantum many-body systems exhibit an exponential scaling of degrees of freedom with system size, which drastically complicates the description of them. However, often the vast majority of states in the Hilbert space are not of physical interest. Ground states of one-dimensional, gapped, local Hamiltonians obey \textit{entanglement area laws}, which effectively puts an upper bound on the entanglement entropy within the system \cite{hastings2007area,eisert2010colloquium}. 
Tensor networks obey area laws by construction \cite{schollwock2011density}, whereby they are ideal for the description of low entanglement systems. By discarding non-contributing eigenstates, tensor networks provide an efficient representation of the system while maintaining high accuracy. Even for systems of high entanglement tensor network provide a low-entanglement effective theory \cite{gillman2018kibble}.\\ 
The \textit{matrix product state} (MPS) is a class of tensor network, which excels at describing lattice systems. The networks are constructed from rank-3 tensors containing an uncontracted \textit{physical index} corresponding to the local Hilbert space (here the Fock space) and up to two internal, virtual \textit{bond indices}. The bond dimension between two sites is directly related to the entanglement between them, as a bond of dimension $\chi$ can have an entanglement entropy of at most $S(\rho_A) = \mathcal{O}(\log \chi)$ \cite{schollwock2011density}.\\
One of the most powerful techniques for investigating one-dimensional systems is the Density Matrix Renormalization Group (DMRG) \cite{white1992density,white1993density}, which provides variational ground state searches while taking advantage of area laws. Time-dependent extensions of DMRG such as the t-DMRG and TEBD methods enables simulations of one-dimensional systems \cite{vidal2003efficient,vidal2004efficient,daley2004time}. Although entropy within the system is expected to increase during a dynamical evolution, it has been shown that a system initially obeying an area law will continue to do so for longer times \cite{bravyi2006lieb,eisert2006general}. This is due to the Lieb-Robinson bounds \cite{lieb1972finite}, which result in a light-cone-like propagation of information within systems evolved by a local Hamiltonian \cite{hastings2006spectral,cheneau2012light}. However, the pre-factor of the area law is expected to grow exponentially \cite{schuch2008entropy}. Therefore, tensor network methods are capable of simulating out-of-equilibrium dynamics on short scales \cite{eisert2015quantum}. 
While a ground state description near a critical point would require an exponential amount of resources due to the diverging entanglement \cite{vidal2003efficient}, the phase transition can be effectively transversed, as the limited propagation velocity of excitations significantly reduces the required bond dimension for describing the dynamics of the system. 


\section{Quantum Optimal Control}

GRADIENT MOTIVATION ....

GRAPE is a popular method for calculating gradients of optimal control cost functionals \cite{khaneja2005optimal}. The method has successfully been applied to EXAMPLES systems. In GRAPE the control function is discretized in time-steps of  $\Delta t$. While the gradient of the cost function in the original algorithm was derived to $O(\Delta t ^2)$ precision, a series of higher order corrections were added in \cite{de2011second}. The derivative of the cost function \eqref{eq:infidelityCost} with respect to the time-discretized control function is
\begin{equation}
	\frac{\partial J}{\partial u_n (t_j)}  = - \Re \Braket{\chi (t_j) | i  \frac{\partial \hat{\mathcal{U}}_{t_j}}{\partial u_n (t_j)} | \psi (t_{j-1})} \; , \label{eq:CostDeriv}
\end{equation}
where $\ket{\chi (T)} \equiv i \ket{\psi_{\mathrm{target}}} \braket{\psi_{\mathrm{target}} | \psi (T)}$ must be propagated back in time to obtain $\ket{\chi (t_j)}$.
The derivative of the propagator with respect to the control is given by
\begin{align}
	\frac{\partial \hat{\mathcal{U}}_{j}}{\partial u_n (t_j)} &= e^{-i \hat{H} (u_n (t_j)) \Delta t} \nonumber \\ 
	 \times \sum_{k = 0}^{\infty } &  \frac{i^{k-1} \Delta t^{k+1}}{(k+1)!} \left[ \hat{H} (u_n (t_j)) , \frac{\partial \hat{H} (u_n (t_j))}{\partial u_n (t_j)}  \right]_k \; , \label{eq:PropDeriv}
\end{align}
where the zeroth order term of the recursive commutator produces the gradient of the original GRAPE algorithm.

Calculating the propagator after each control update is an expensive procedure, as exponentiating the Hamiltonian \eqref{eq:ControlHamiltonians} is non-trivial. The Hamiltonian can be exponentiated term-wise through the Suzuki-Trotter expansion
\begin{equation}
		e ^{( \hat{H}_n + \hat{H}_0  ) \delta } = e^{  \hat{H}_n \delta /2  } e^{ \hat{H}_0 \delta } e^{ \hat{H}_n \delta /2 } + O(\delta^3) \; , \label{eq:SuzukiTrotter}
\end{equation}
where the error is due to any non-commutativity of the operators.
Thus, the propagator can be updated efficiently, as only $e^{ \hat{H}_n \delta /2 }$ must be re-calculated as $u_n (t)$ is updated. Additionally, Trotter-expanding the propagator is a necessary step for conducting time-evolution through the tDMRG algorithm. 

Further improvements in the cost of computing the propagator can be found if $\hat{H}_n$ is diagonal, as the exponentiation becomes trivial. Choosing a diagonal control Hamiltonian also has profound impact on the  derivative of the propagator, as all higher-order contributions vanish.\\
Consider a Suzuki-Trotter expanded propagator, where $\hat{H}_n (u_n (t))$ is evaluated at either side of the time-step for increased accuracy
\begin{align}
	\hat{\mathcal{U}}_{j}^{\mathrm{ST}} &\equiv e^{ -i  \hat{H}_n (u (t_j)) \Delta t /2 } \; e^{ -i \hat{H}_0 \Delta t } \; e^{ -i  \hat{H}_n (u (t_{j-1}))  \Delta t /2 } \\
	& \equiv \hat{\mathcal{U}}_{j}^{(n)} \hat{\mathcal{U}}_{j}^{(0)} \hat{\mathcal{U}}_{j-1}^{(n)} \; .
\end{align}
Both $\mathcal{U}_{j}^{\mathrm{ST}}$ and $\mathcal{U}_{j+1}^{\mathrm{ST}}$ contribute to the cost derivative due to the split-step of the control.
The derivative of $\mathcal{U}_{j}^{\mathrm{ST}}$ according to eq. \eqref{eq:PropDeriv} is
\begin{align}
	\frac{\partial \hat{\mathcal{U}}_{j}^{\mathrm{ST}}}{\partial u_n (t_j)} &=  \frac{\partial \hat{\mathcal{U}}_{j}^{(n)}}{\partial u_n (t_j)} \hat{\mathcal{U}}_{j}^{(0)} \hat{\mathcal{U}}_{j-1}^{(n)} \nonumber \\
	&= e^{ -i  \hat{H}_n (u (t_j)) \Delta t /2 } \left( -i \frac{\partial \hat{H} (u_n (t_j))}{\partial u_n (t_j)} \Delta t /2 \right) \hat{\mathcal{U}}_{j}^{(0)} \hat{\mathcal{U}}_{j-1}^{(n)} \nonumber \\
	&= \left( -i \frac{\partial \hat{H} (u_n (t_j))}{\partial u_n (t_j)} \Delta t /2 \right) \hat{\mathcal{U}}_{j}^{\mathrm{ST}} \; . \label{eq:STpropderiv1}
\end{align}
Since $\hat{H}_n$ is diagonal, the recursive commutator is vanishing for $k > 0$, which causes all higher-order contributions to the derivative of the propagator to drop out.\\
Likewise, the derivative of the second propagator is
\begin{equation}
	\frac{\partial \hat{\mathcal{U}}_{j+1}^{\mathrm{ST}}}{\partial u_n (j)} =  \hat{\mathcal{U}}_{j+1}^{\mathrm{ST}} \left( -i \frac{\partial \hat{H} (u_n (t_j))}{\partial u_n (t_j)} \Delta t /2 \right) \; . \label{eq:STpropderiv2}
\end{equation}
Inserting the derivatives of eq. \eqref{eq:STpropderiv1} and \eqref{eq:STpropderiv2} into the derivative of the cost (eq. \eqref{eq:CostDeriv}) yields
\begin{align}
	\frac{\partial J}{\partial u_n (t_j)} &= - \Re \Braket{\chi (t_j) |  \left(  \frac{\partial \hat{H} (u_n (t_j))}{\partial u_n (t_j)} \Delta t /2 \right) \hat{\mathcal{U}}_{j}^{\mathrm{ST}} | \psi (t_{j-1})} \nonumber \\
	& \quad - \Re \Braket{\chi (t_{j+1}) | \hat{\mathcal{U}}_{j+1}^{\mathrm{ST}} \left(  \frac{\partial \hat{H} (u_n (t_j))}{\partial u_n (t_j)} \Delta t /2 \right) | \psi (t_{j})} \nonumber \\
	&= - \Re \Braket{\chi (t_j) | \frac{\partial \hat{H} (u_n (t_j))}{\partial u_n (t_j)} \Delta t | \psi (t_{j})} \; . \label{eq:STcostgrad}
\end{align}  
Thus, the combination of the Suzuki-Trotter expansion and a diagonal control Hamiltonian eliminates all higher order contributions to the gradient. Thereby, the gradient of the cost is exact up to the order of the expansion.

